{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bismi Allah**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projet d'ARN de fin de semestre**\n",
    "\n",
    "\n",
    "        Travail réalisé par le binôme : \n",
    "            - SAYOUD Maissa 191931040670\n",
    "            - BOULKABOUL Amira 202031043294\n",
    "\n",
    "    Etudiantes en M1 SII Groupe 02\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Etape 0: Importation des Bibliothèques & Chargement des Données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt\\nimport cv2\\n\\nfrom sklearn.metrics import log_loss\\nfrom sklearn.neural_network import MLPClassifier\\n\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nfrom nltk.stem import PorterStemmer\\nfrom bs4 import BeautifulSoup'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour mettre les données dans un dataset pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# pour generer des nombre aleatoires\n",
    "import random\n",
    "\n",
    "# pour les expression régulieres (regex)\n",
    "import re\n",
    "\n",
    "# pour la vectorisation\n",
    "import numpy as np\n",
    "\n",
    "#pour les chaines de caracteres\n",
    "import string\n",
    "\n",
    "# pour supprimer les stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\",\".join(stopwords.words('english'))\n",
    "stop_words=set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# pour la tokenisation \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import spacy\n",
    "\n",
    "# pour le stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Pour lemmatisation \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données du Dataset \"sentiment140\"\n",
    "Pour jeter un coup d'oeil à des exemples de l'ensemble de données à traiter !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", \n",
    "                      header=None, \n",
    "                      encoding=\"ISO-8859-1\",\n",
    "                      names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "                      )\n",
    "\n",
    "print(dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de 3 données aléatoires du Dataset \"sentiment140\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Visualiser le tweet N° :  1572803\n",
      "target :  4\n",
      "ids  :  2188988098\n",
      "date :  Mon Jun 15 22:59:54 PDT 2009\n",
      "flag :  NO_QUERY\n",
      "user :  zdnetaustralia\n",
      "text :  We couldn't resist this little headline fun on Superwoman   http://bit.ly/Ooe61 *chortle*\n",
      "\n",
      " Visualiser le tweet N° :  136293\n",
      "target :  0\n",
      "ids  :  1880065846\n",
      "date :  Thu May 21 23:59:47 PDT 2009\n",
      "flag :  NO_QUERY\n",
      "user :  MZenani\n",
      "text :  @ilikecupcakes that?sucks balls. I'm sorry. A Toyota clipped my back wheel when I was changing lanes on the 105 and he sped up to stop me \n",
      "\n",
      " Visualiser le tweet N° :  418155\n",
      "target :  0\n",
      "ids  :  2061701792\n",
      "date :  Sat Jun 06 21:25:37 PDT 2009\n",
      "flag :  NO_QUERY\n",
      "user :  cmrush\n",
      "text :  @willychu hardware error. People couldn't hear me speaking through the phone.  PS eating @ asuka ramen... So yummy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nombre_tweets = 3\n",
    "\n",
    "r = random.sample(range(len(dataset)), nombre_tweets)\n",
    "\n",
    "for i in r:\n",
    "    print(\" Visualiser le tweet N° : \", i+1)\n",
    "    \n",
    "    print(\"target : \",dataset.iloc[i][\"target\"])\n",
    "    print(\"ids  : \",dataset.iloc[i][\"ids\"])\n",
    "    print(\"date : \",dataset.iloc[i][\"date\"])\n",
    "    print(\"flag : \",dataset.iloc[i][\"flag\"])\n",
    "    print(\"user : \",dataset.iloc[i][\"user\"])\n",
    "    print(\"text : \",dataset.iloc[i][\"text\"])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Étape 1 : Préparation des Données**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **A. Nettoyage des Tweets** :\n",
    "\n",
    "- **Supprression des colonnes inutiles**\n",
    "\n",
    "- **Minuscule** : l'intégralité du tweet devra être convertie en minuscules.  \n",
    "\n",
    "- **Suppression de balises HTML** : Toutes les balises HTML devront être supprimées.  \n",
    "\n",
    "- **Radicalisation de mots** : Les mots devront être réduits à leur forme radicale.\n",
    "\n",
    "- **Suppression des non-mots** : les non-mots et la ponctuation devront être supprimés. Tous les espaces blancs (onglets, nouvelles lignes, espaces) devront être remplacés par un seul espace. \n",
    "\n",
    "- **Suppression des mots vides** : les mots tel que « a, the, this,… » devront être supprimés.\n",
    "\n",
    "- **Remplacement de label 4 par label 1**.\n",
    "\n",
    "etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Suppression des colonnes inutiles**\n",
    "Les colonnes comme \"ids\", \"date\", \"flag\" et \"user\" ne sont pas nécessaires pour\n",
    "l'analyse de sentiment. Nous gardons que le texte des tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape : (1600000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les colonnes inutiles\n",
    "dataset.drop(columns=[\"ids\", \"date\", \"flag\", \"user\"], inplace=True)\n",
    "\n",
    "print(\"New shape :\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fonctions de Nettoyage des Données**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour supprimer les URL\n",
    "def remove_url(input_text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour supprimer les balises HTML:\n",
    "def remove_html_tags(input_text):\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(html, '', input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour supprimer les tags (@user):\n",
    "def remove_pattern(input_text, pattern):\n",
    "    r = re.findall(pattern, input_text)\n",
    "    for word in r:\n",
    "        input_text = re.sub(word, \"\", input_text)\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour supprimer les non-words et la poctuation \n",
    "def remove_non_words(input_text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', input_text)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour supprimer les blancs:\n",
    "def remove_gaps(input_text):\n",
    "    texte_propre = re.sub(r'\\s+', ' ', input_text)\n",
    "    return texte_propre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focntion pour supprimer les mots vides :\n",
    "def remove_stop_words (input_text):\n",
    "    return \" \".join([ word for word in str(input_text).split() if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour convertir les tweets en minuscule:\n",
    "def lower_text(input_text):\n",
    "    return input_text.lower() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset avant cleaning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel des fonctions et autres inctructions pour le nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des liens URL\n",
    "dataset['clean_tweet'] = dataset['text'].apply(lambda x: remove_url(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des balises HTML\n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: remove_html_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des tags (@user)\n",
    "dataset['clean_tweet'] = np.vectorize(remove_pattern)(dataset['clean_tweet'], \"@[\\w]*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des non-words (y compris la ponctuation)\n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: remove_non_words(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des mots courts\n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w) >= 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion en minuscule \n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer stop word (at, the, etc.)\n",
    "dataset[\"clean_tweet\"] = dataset[\"clean_tweet\"].apply(lambda x : remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des blancs\n",
    "dataset['clean_tweet'] = dataset['clean_tweet'].apply(lambda x: remove_gaps(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset après le cleaning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdb com cool hear old walt interviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>ready mojo makeover ask details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happy birthday boo alll time tupac amaru shakur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "1599995       4  Just woke up. Having no school is the best fee...   \n",
       "1599996       4  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997       4  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998       4  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999       4  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "1599995                    woke school best feeling ever  \n",
       "1599996         thewdb com cool hear old walt interviews  \n",
       "1599997                  ready mojo makeover ask details  \n",
       "1599998  happy birthday boo alll time tupac amaru shakur  \n",
       "1599999                             happy charitytuesday  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation, Radicalisation (Stemming) & Lemmatisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Tokenize the text using spaCy\n",
    "    tokens = nlp(text)\n",
    "    \n",
    "    # Lemmatize and stem each token, and remove punctuation and stop words\n",
    "    processed_tokens = [lemmatizer.lemmatize(stemmer.stem(token.text)) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"tokens\"] = dataset[\"clean_tweet\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest bounds</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving mad see</td>\n",
       "      <td>behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1       0  is upset that he can't update his Facebook by ...   \n",
       "2       0  @Kenichan I dived many times for the ball. Man...   \n",
       "3       0    my whole body feels itchy and like its on fire    \n",
       "4       0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0       awww bummer shoulda got david carr third day   \n",
       "1  upset update facebook texting might cry result...   \n",
       "2     dived many times ball managed save rest bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                                   behaving mad see   \n",
       "\n",
       "                                              tokens  \n",
       "0       awww bummer shoulda got david carr third day  \n",
       "1  upset updat facebook text might cri result sch...  \n",
       "2          dive mani time ball manag save rest bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                                      behav mad see  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplacer les labels 4 par les labels 1\n",
    "0 --> tweet negatif\n",
    "\n",
    "1 --> tweet positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer 4 par 1 :\n",
    "dataset['target'] = dataset['target'].replace(4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feeling ever</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdb com cool hear old walt interviews</td>\n",
       "      <td>thewdb com cool hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>ready mojo makeover ask details</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happy birthday boo alll time tupac amaru shakur</td>\n",
       "      <td>happi birthday boo alll time tupac amaru shakur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "1599995       1  Just woke up. Having no school is the best fee...   \n",
       "1599996       1  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997       1  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998       1  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999       1  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "1599995                    woke school best feeling ever   \n",
       "1599996         thewdb com cool hear old walt interviews   \n",
       "1599997                  ready mojo makeover ask details   \n",
       "1599998  happy birthday boo alll time tupac amaru shakur   \n",
       "1599999                             happy charitytuesday   \n",
       "\n",
       "                                                  tokens  \n",
       "1599995                       woke school best feel ever  \n",
       "1599996          thewdb com cool hear old walt interview  \n",
       "1599997                     readi mojo makeov ask detail  \n",
       "1599998  happi birthday boo alll time tupac amaru shakur  \n",
       "1599999                             happi charitytuesday  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset apres changement de label target et suppression des colonnes inutiles\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest bounds</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving mad see</td>\n",
       "      <td>behav mad see</td>\n",
       "      <td>behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1       0  is upset that he can't update his Facebook by ...   \n",
       "2       0  @Kenichan I dived many times for the ball. Man...   \n",
       "3       0    my whole body feels itchy and like its on fire    \n",
       "4       0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0       awww bummer shoulda got david carr third day   \n",
       "1  upset update facebook texting might cry result...   \n",
       "2     dived many times ball managed save rest bounds   \n",
       "3                   whole body feels itchy like fire   \n",
       "4                                   behaving mad see   \n",
       "\n",
       "                                              tokens  \\\n",
       "0       awww bummer shoulda got david carr third day   \n",
       "1  upset updat facebook text might cri result sch...   \n",
       "2          dive mani time ball manag save rest bound   \n",
       "3                    whole bodi feel itchi like fire   \n",
       "4                                      behav mad see   \n",
       "\n",
       "                                             tokens_  \n",
       "0       awww bummer shoulda got david carr third day  \n",
       "1  upset updat facebook text might cri result sch...  \n",
       "2          dive mani time ball manag save rest bound  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                                      behav mad see  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supprimer les mots courts de nouveau\n",
    "dataset['tokens_'] = dataset['tokens'].apply(lambda x: ' '.join([w for w in x.split() if len(w) >= 3]))\n",
    "\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape : (1600000, 2)\n"
     ]
    }
   ],
   "source": [
    "# suppression des colonnes non utiles\n",
    "dataset.drop(columns=[\"text\", \"clean_tweet\", \"tokens\"], inplace=True)\n",
    "\n",
    "print(\"New shape :\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le nouveau dataset preprocessed dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le dataset nettoyé dans un nouveau fichier\n",
    "dataset.to_csv(\"sentiment140_preprocessed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annoncer la fin du Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "import time\n",
    "\n",
    "frequency = 440  \n",
    "duration = 1000  # 1 seconde\n",
    "\n",
    "winsound.Beep(frequency, duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez trouver la suite du programme dans le fichier projet2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
